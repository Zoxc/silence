use "lexer"
use "type-ast"

data Parser
	Lexer* lexer
	Compiler* compiler

	action create(lexer) :
		lexer <- lexer,
		compiler <- lexer.compiler

	fn tok()
		return lexer.tok.type

	fn eq(Token v)
		return v == tok()

	fn format_token() -> String
		return tok().str()

	fn step()
		lexer.next_token()

	fn array[T]() -> Array[T, Region]
		return Array[T, Region](lexer.region())

	fn ast[T, R] *args
		var R* r = Callable(lexer.region().new[T]).apply(args)
		return r

	fn extend(SrcLoc* src)
		src.stop = lexer.tok.last_ended

	fn expected_str(String str)
		lexer.report[Error.ExpectedString](lexer.src(), str.copy(compiler.region.ref()))

	fn expected(Token tok)
		lexer.report[Error.ExpectedToken](lexer.src(), tok, format_token().copy(compiler.region.ref()))

	fn ensure(Token v)
		if v == tok()
			step()
		else
			expected(v)

	fn skip_line()
		if tok() == Token.Line
			lexer.next_token_after_line()

	fn get_ident()
		return if tok() == Token.Ident
			var r = some lexer.tok.symbol
			step()
			r
		else
			nil

	fn matches(token)
		return if tok() == token
			step()
			true
		else
			false

	fn matches_ident(Symbol *ident)
		return if tok() == Token.Ident
			if ident == lexer.tok.symbol
				step()
				true
			else
				false
		else
			false

	fn sep()
		ensure(Token.Line)

	fn src(a)
		var s = lexer.src()
		var r = a(s)
		s.stop = lexer.tok.last_ended
		return r

	# Global scope and program

	fn program()
		global_entries -> tok() == Token.EndOfFile
		if tok() != Token.EndOfFile
			expected(Token.EndOfFile)

	fn global_entries(term)
		loop
			if !global_entry()
					break
			if term()
				break
			sep()

	fn global_entry() -> bool
		match tok()
			when Token.Ident
				match lexer.tok.symbol
					when Symbol.kw_data
						data()
						return true
					else
						return false
			else
				return false

		return true

	fn data()
		var s = lexer.src()
		var baseline = lexer.tok.indent
		step()
		var sizeable = !matches_ident(Symbol.kw_ref)
		var name = get_ident()
		kind_params()
		extend s
		var scope = global_scope(baseline)

	fn kind_params() -> () constraints
		src \s ->
			if matches(Token.SquareOpen)
				skip_line()
				var params = type_params()
				ensure(Token.SquareClose)

	fn type_args(Array[TypeNode*, Region]* args)

		loop
			type_operator()
			if matches(Token.Comma)
				skip_line()
			else
				break

	fn type_params()
		src \s ->
			var type = type_expression()
			var value = false
			var name = nil
			if eq(Token.Ident)
				name = get_ident()
			else if matches(Token.DoubleColon)
				skip_line()
				name = get_ident()
				value = true
			else
				type = nil

			kind_params()
			if matches(Token.Assign)
				skip_line()
				if value
					expression
				else
					type_expression

	fn is_type_expression()
		return match tok()
			when Token.Ident, Token.Number, Token.String, Token.ParentOpen
				true
			else
				false

	fn type_operator()
		var r = type_expression()

		loop
			if !eq(Token.ArrowRight)
				break

			step()
			skip_line()

			type_expression()

		return r

	fn type_expression() -> Option[TypeNode*] constraints
		type_ptr()

	fn type_ptr()
		var r = type_chain()

		loop
			if !eq(Token.Mul)
				break

			step()

		return r

	fn type_chain()
		var r = type_factor()

		loop
			match tok()
				when Token.SquareOpen
					step()
					skip_line()
					var args = array()
					type_args(&args)
					ensure(Token.SquareClose)
				when Token.Dot
					step()
					skip_line()
					var name = get_ident()
				else
					break

		return r

	fn type_tuple(s)
		step()
		skip_line()

		var nodes = array()

		if !eq(Token.ParentClose)
			type_args(&nodes)

		ensure(Token.ParentClose)

		return ast[TypeNode.Tuple](s, nodes)

	fn type_factor()
		return src \s ->
			return match tok()
				when Token.ParentOpen
					type_tuple(s)
				when Token.Number
					var r = ast[TypeNode.Number](s)
					step()
					r
				when Token.Ident
					if matches_ident(Symbol.kw_typeof)
						chain()
						ast[TypeNode.Typeof](s)
					else
						var r2 = ast[TypeNode.Ref](s, lexer.tok.symbol)
						step()
						r2
				else
					expected_str("type")
					ast[TypeNode.Error](s)

	fn global_scope(baseline)

	fn expression()

	fn chain()
use "lexer"

data Parser
	Lexer* lexer
	Compiler* compiler

	action create(lexer) :
		lexer <- lexer,
		compiler <- lexer.compiler

	fn tok()
		return lexer.tok.type

	fn format_token() -> String
		return tok().str()

	fn step()
		lexer.next_token()

	fn extend(SrcLoc* src)
		src.stop = lexer.tok.last_ended

	fn expected(Token tok)
		lexer.report[Error.ExpectedToken](lexer.src(), tok, format_token().copy(compiler.region.ref()))

	fn ensure(Token v)
		if v == tok()
			step()
		else
			expected(v)

	fn get_ident()
		return if tok() == Token.Ident
			some lexer.tok.str()
		else
			nil

	fn matches_ident(String ident)
		return if tok() == Token.Ident
			ident == lexer.tok.str()
		else
			false

	fn program()
		var r = global_entries -> tok() == Token.EndOfFile
		if tok() != Token.EndOfFile
			expected(Token.EndOfFile)
		return r

	fn sep()
		ensure(Token.Line)

	fn src(a)
		var s = lexer.src()
		a(s)
		s.stop = lexer.tok.last_ended

	fn global_entries(term)
		loop
			if !global_entry()
					break
			if term()
				break
			sep()

	fn global_entry() -> bool
		match tok()
			when Token.Ident
				IO.puts("Test |" ~ lexer.tok.str() ~ "|")
				match lexer.tok.str()
					when "struct"
						struct()
					else
						return false
			else
				return false

		return true

	fn struct()
		var s = lexer.src()
		var baseline = lexer.tok.indent
		step()
		var sizeable = !matches_ident("ref")
		var name = get_ident()
		var tp = kind_params()
		extend s
		var scope = global_scope(baseline)

	fn kind_params()

	fn global_scope(baseline)